{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a custom pipeline\n",
    "\n",
    "The **deep**doctection analyzer is an example of a Document Layout Analysis pipeline. In this tutorial we'll show you the concepts so that you can build a pipeline yourself and according the needs you have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import deepdoctection as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is not that difficult: There are **models** that fulfill a given task, there are **pipeline components** or **pipeline backbones** that invoke models and take care of pre- and post-processing results. There are also pipeline backbones that do not invoke models but only consolidate results. \n",
    "\n",
    "And there is the **pipeline** that puts everything together.\n",
    "\n",
    "## Catalog and registries\n",
    "\n",
    "You can get the essential information for pre-trained model from the `ModelCatalog`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.print_model_infos(add_description=False,add_config=False,add_categories=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select fasttext language detector. We need the categories that the model predicts and the model wrapper. `fasttext/lid.176.bin` is just an artifact. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=dd.ModelCatalog.get_profile(\"fasttext/lid.176.bin\").categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FasttextLangDetector'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.ModelCatalog.get_profile(\"fasttext/lid.176.bin\").model_wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can download `lid.176.bin` with help of the `ModelDownloadManager`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0622 09:29.50 @fs.py:94]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mFile lid.176.bin exists! Skip download.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "path_weights=dd.ModelDownloadManager.maybe_download_weights_and_configs(\"fasttext/lid.176.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model wrapper\n",
    "\n",
    "We know from the `ModelCatalog` which wrapper we must use for the fasttext model, namely `FasttextLangDetector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_text = dd.FasttextLangDetector(path_weights, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not done yet, because we still need to choose how to extract text. Let's simply stick to Tesseract and use the default english setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tess_ocr_config_path = dd.get_configs_dir_path() / \"dd/conf_tesseract.yaml\"  # This file will be in your .cache if you ran the analyzer before. \n",
    "# Otherwise make sure to copy the file from 'configs/conf_tesseract.yaml'\n",
    "\n",
    "tesseract_ocr = dd.TesseractOcrDetector(tess_ocr_config_path.as_posix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline backbone\n",
    "\n",
    "Similar to models we have a pipeline component registry. Having this starting point we can select the right backbone. Check the API documentation to see what the components are used for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SubImageLayoutService': deepdoctection.pipe.cell.SubImageLayoutService,\n",
       " 'ImageCroppingService': deepdoctection.pipe.concurrency.MultiThreadPipelineComponent,\n",
       " 'MatchingService': deepdoctection.pipe.common.MatchingService,\n",
       " 'PageParsingService': deepdoctection.pipe.common.PageParsingService,\n",
       " 'AnnotationNmsService': deepdoctection.pipe.common.AnnotationNmsService,\n",
       " 'ImageParsingService': deepdoctection.pipe.common.ImageParsingService,\n",
       " 'LanguageDetectionService': deepdoctection.pipe.language.LanguageDetectionService,\n",
       " 'ImageLayoutService': deepdoctection.pipe.layout.ImageLayoutService,\n",
       " 'LMTokenClassifierService': deepdoctection.pipe.lm.LMTokenClassifierService,\n",
       " 'LMSequenceClassifierService': deepdoctection.pipe.lm.LMSequenceClassifierService,\n",
       " 'TextOrderService': deepdoctection.pipe.order.TextOrderService,\n",
       " 'TableSegmentationRefinementService': deepdoctection.pipe.refine.TableSegmentationRefinementService,\n",
       " 'TableSegmentationService': deepdoctection.pipe.segment.TableSegmentationService,\n",
       " 'TextExtractionService': deepdoctection.pipe.text.TextExtractionService,\n",
       " 'SimpleTransformService': deepdoctection.pipe.transform.SimpleTransformService}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.pipeline_component_registry.get_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext language detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_detect_comp = dd.LanguageDetectionService(fast_text,text_detector=tesseract_ocr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now build our very simple pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_comp_list = [lang_detect_comp]\n",
    "pipe = dd.DoctectionPipe(pipeline_component_list=pipe_comp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = Path.cwd() / \"pics/samples/sample_3\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./pics/samples/sample_3/sample_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running the pipe, we get the language the document was written. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pipe.analyze(path=image_path)\n",
    "df.reset_state()\n",
    "dp = next(iter(df))\n",
    "dp.language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When getting the text, the response is somewhat disappointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason for that is that `LanguageDetectionService` is not responsible for extracting text. It has an OCR model, but the output is only used as input feed to the language detector. The text however is not persisted. If we had added a `TextExtractionService` before `LanguageDetectionService` we could have omitted the OCR model in the `LanguageDetectionService`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tesseract OCR detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesseract_ocr = dd.TesseractOcrDetector(tess_ocr_config_path.as_posix(),[\"LANGUAGES=deu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LANGUAGES': 'deu', 'LINES': False, 'psm': 11}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesseract_ocr.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting run_time_ocr_language_selection=True will dynamically select the OCR model for text extraction based on \n",
    "# the predicted languages. This helps to get much improved OCR results, if you have documents with various languages.\n",
    "\n",
    "text_comp = dd.TextExtractionService(tesseract_ocr, run_time_ocr_language_selection=True)\n",
    "pipe_comp_list.append(text_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pipe.analyze(path=image_path)\n",
    "df.reset_state()\n",
    "dp = next(iter(df))\n",
    "dp.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is something unexpected. Why don't we generate any text? We can clearly see that the `TextExtractionService` did its job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(553, 'Anleihem√§rkte', [137.0, 158.0, 472.0, 195.0], None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_sample = dp.words[0]\n",
    "len(dp.words), word_sample.characters, word_sample.bbox, word_sample.reading_order "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text ordering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason is, that we do not have inferred a reading order. If there is no reading order, there is no contiguous text. We treat text extraction as a character recognition problem only. If we want a reading order of predicted words, we need to do it ourself. So let's add the `TextOrderService`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_comp = dd.TextOrderService(text_container=dd.LayoutType.word)\n",
    "pipe_comp_list.append(order_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least, we got some text. The beginning sounds good. But once the text comes to the region where the second and third column also have text lines, the order service does not distinguish between columns. So we must identify columns. For that we use the layout analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pipe.analyze(path=image_path)\n",
    "df.reset_state()\n",
    "dp = next(iter(df))\n",
    "dp.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layout service\n",
    "\n",
    "It now depends on whether we use Tensorflow or PyTorch. We opt for PyTorch, just because the model runs on a CPU.\n",
    "Make sure, that the model has been loaded to your .cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': <LayoutType.text>,\n",
       " '2': <LayoutType.title>,\n",
       " '3': <LayoutType.list>,\n",
       " '4': <LayoutType.table>,\n",
       " '5': <LayoutType.figure>}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_weights = dd.ModelCatalog.get_full_path_weights(\"layout/d2_model_0829999_layout_inf_only.pt\")\n",
    "path_configs = dd.ModelCatalog.get_full_path_configs(\"layout/d2_model_0829999_layout_inf_only.pt\")\n",
    "categories = dd.ModelCatalog.get_profile(\"layout/d2_model_0829999_layout_inf_only.pt\").categories\n",
    "\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_detector = dd.D2FrcnnDetector(path_configs,path_weights,categories,device=\"cpu\")\n",
    "layout_comp = dd.ImageLayoutService(layout_detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make sure, that the `ImageLayoutService` has been invoked before `TextOrderService`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_comp_list.insert(0,layout_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pipe.analyze(path=image_path)\n",
    "df.reset_state()\n",
    "dp = next(iter(df))\n",
    "dp.layouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\\nAnleihem√§rkte im Gesch√§ftsjahr\\nbis zum 31.12.2018\\n\\nUS-Notenbank.\\nSchwieriges Marktumfeld\\nDie internationalen Anleihe- %p.a.\\nm√§rkte entwickelten sich im\\nGesch√§ftsjahr 2018 unter-\\nschiedlich und phasenweise\\nsehr volatil. Dabei machte sich\\nbei den Investoren zunehmend\\nNervosit√§t breit, was in steigen-\\nden Risikopr√§mien zum Aus-\\n12/08 12/09 12/10 12/11 12/12 12/13 12/14 12/15 12/16 12/17 12/18\\ndruck kam. Grund hierf√ºr waren\\nBE Fed-Leitzins\\nQuelle: Thomson Financial Datastream\\nTurbulenzen auf der weltpoli-\\nBE E28-Leitzins\\nStand: 31.12.2018\\ntischen B√ºhne, die die politi-\\nschen Risiken erh√∂hten. Dazu\\n\\nz√§hlten unter anderem populis-\\nZinswende nach Rekordtiefs\\nFiskalpolitik des US-Pr√§sidenten\\ntische Str√∂mungen nicht nur\\nbei Anleiherenditen?\\nDonald Trump in Form von\\nin den USA und Europa, auch\\nIm Berichtszeitraum kam es an\\nSteuererleichterungen und einer\\nin den Emerging Markets, wie\\nden Anleihem√§rkten - wenn\\nErh√∂hung der Staatsausgaben\\nzuletzt in Brasilien und Mexiko,\\nauch uneinheitlich und unter-\\nnoch befeuert wurde. Vor die-\\nwo Populisten in die Regie-\\nschiedlich stark ausgepr√§gt -\\nsem Hintergrund verzeichneten\\nHaushaltspolitik auf Konfronta-\\nUSA weiter von ihren histori-\\nvon 2,4% p.a. auf 3,1% p.a.\\ntionskurs zur Europ√§ischen Uni-\\nschen Tiefs l√∂sen. Gleichzeitig\\non (EU). Dar√ºber hinaus verun-\\nwurde die Zentralbankdivergenz\\nDiese Entwicklung in den USA\\n\\nsicherte weiterhin der drohende\\nzwischen den USA und dem\\nhatte auf den Euroraum jedoch\\nBrexit die Marktteilnehmer,\\nEuroraum immer deutlicher. An-\\nnur phasenweise und partiell,\\ninsbesondere dahingehend, ob\\ngesichts des Wirtschaftsbooms\\ninsgesamt aber kaum einen\\nder m√∂gliche Austritt des Ver-\\nin den USA hob die US-Noten-\\nzinstreibenden Effekt auf Staats-\\neinigten K√∂nigreiches aus der\\nbank Fed im Berichtszeitraum\\nanleihen aus den europ√§ischen\\nEU geordnet oder - ohne ein\\nden Leitzins in vier Schritten\\nKernm√§rkten wie beispielsweise\\n√úbereinkommen - ungeordnet\\nweiter um einen Prozentpunkt\\nDeutschland und Frankreich.\\nvollzogen wird. Im Gegensatz\\nauf einen Korridor von 2,25% -\\nSo gaben zehnj√§hrige deutsche\\nzu den politischen Unsicher-\\n2,50% p.a. an. Die Europ√§ische\\nBundesanleihen im Jahresver-\\nheiten standen die bislang eher\\nZentralbank (EZB) hingegen\\nlauf 2018 unter Schwankungen\\nIn den Monaten Mai und Juni\\n\\nEntwicklung der Leitzinsen in den USA und im Euroraum\\n\\n\\nrungen gew√§hlt wurden. Der\\nunter Schwankungen zu stei-\\ndie US-Bondm√§rkte einen sp√ºr-\\neskalierende Handelskonflikt\\ngenden Renditen auf teilweise\\nbaren Renditeanstieg, der mit\\nzwischen den USA einerseits\\nimmer noch sehr niedrigem\\nmerklichen Kurserm√§√üigungen\\nsowie Europa und China ande-\\nNiveau, begleitet von nachge-\\neinherging. Per saldo stiegen\\nrerseits tat sein √ºbriges. Zudem\\nbenden Kursen. Dabei konnten\\ndie Renditen zehnj√§hriger US-\\nging Italien im Rahmen seiner\\nsich die Zinsen vor allem in den\\nStaatsanleihen auf Jahressicht\\nzuversichtlichen, konventionel-\\nhielt an ihrer Nullzinspolitik fest\\nper saldo sogar von 0,42% p.a.\\nlen Wirtschaftsindikatoren. So\\nund die Bank of Japan belie√ü\\nauf 0,25% p. a. nach. Vielmehr\\nexpandierte die Weltwirtschaft\\nihren Leitzins bei -0,10% p.a.\\nstanden die Anleihem√§rkte\\nkr√§ftig, wenngleich sich deren\\nDie Fed begr√ºndete ihre Zinser-\\nder Eurol√§nder - insbeson-\\nWachstum im Laufe der zwei-\\nh√∂hungen mit der Wachstums-\\ndere ab dem zweiten Quartal\\nten Jahresh√§lfte 2018 etwas\\nbeschleunigung und der Voll-\\n2018 - unter dem Einfluss der\\nverlangsamte. Die Geldpolitik\\nbesch√§ftigung am Arbeitsmarkt\\npolitischen und wirtschaftlichen\\nwar historisch gesehen immer\\nin den USA. Zinserh√∂hungen\\nEntwicklung in der Eurozone,\\nnoch sehr locker, trotz der welt-\\nerm√∂glichten der US-Notenbank\\nvor allem in den L√§ndern mit\\nweit sehr hohen Verschuldung\\neiner √úberhitzung der US-Wirt-\\nhoher Verschuldung und nied-\\nund der Zinserh√∂hungen der\\nschaft vorzubeugen, die durch\\nrigem Wirtschaftswachstum.\\ndie prozyklische expansive\\n-1 u\\nu\\nu\\nu\\nu\\nu\\nu\\nu\\nu\\nu u\\n',\n",
       " '')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.text, dp.layouts[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this looks weird again, doesn't it? However the reason is still quite simple. We now get an empty text string because once we have a non-empty `dp.layouts` the routine responsible for creating `dp.text` will try to get the text from the `Layout`'s. But we haven't run any method that maps a `word` to some `Layout` object. We need to specify this by applying a `MatchingService`. We will also have to slightly change the configuration of the  `TextOrderService`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_comp = dd.MatchingService(parent_categories=[\"text\",\"title\",\"list\",\"table\",\"figure\"], child_categories=[\"word\"],\n",
    "                             matching_rule = 'ioa', threshold=0.6) # same setting as for the deepdoctection analyzer\n",
    "\n",
    "order_comp = dd.TextOrderService(text_container=dd.LayoutType.word,\n",
    "                                 floating_text_block_categories=[\"text\",\"title\",\"list\", \"figure\"],\n",
    "                                 text_block_categories=[\"text\",\"title\",\"list\",\"table\",\"figure\"])\n",
    "\n",
    "pipe_comp_list = [layout_comp, lang_detect_comp, text_comp, map_comp, order_comp]\n",
    "pipe = dd.DoctectionPipe(pipeline_component_list=pipe_comp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|                                                                                                                                                                                                 |1/?[00:00<00:00,1346.05it/s]\n",
      "\u001b[32m[0622 09:35.44 @doctectionpipe.py:84]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mProcessing sample_3.png\u001b[0m\n",
      "\u001b[32m[0622 09:35.46 @context.py:126]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mImageLayoutService total: 1.6236 sec.\u001b[0m\n",
      "\u001b[32m[0622 09:35.48 @context.py:126]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mLanguageDetectionService total: 2.6801 sec.\u001b[0m\n",
      "/home/janis/Public/deepdoctection_pt/deepdoctection/deepdoctection/pipe/text.py:114: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if predictor_input in [b\"\"]:\n",
      "\u001b[32m[0622 09:35.51 @context.py:126]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mTextExtractionService total: 2.6963 sec.\u001b[0m\n",
      "\u001b[32m[0622 09:35.51 @context.py:126]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mMatchingService total: 0.0041 sec.\u001b[0m\n",
      "\u001b[32m[0622 09:35.51 @context.py:126]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[97mTextOrderService total: 0.0329 sec.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Anleihem√§rkte im Gesch√§ftsjahr bis zum 31.12.2018\\nSchwieriges Marktumfeld Die internationalen Anleihe- m√§rkte entwickelten sich im Gesch√§ftsjahr 2018 unter- schiedlich und phasenweise sehr volatil. Dabei machte sich bei den Investoren zunehmend Nervosit√§t breit, was in steigen- den Risikopr√§mien zum Aus- druck kam. Grund hierf√ºr waren Turbulenzen auf der weltpoli- tischen B√ºhne, die die politi- schen Risiken erh√∂hten. Dazu z√§hlten unter anderem populis- tische Str√∂mungen nicht nur in den USA und Europa, auch in den Emerging Markets, wie zuletzt in Brasilien und Mexiko, wo Populisten in die Regie- rungen gew√§hlt wurden. Der eskalierende Handelskonflikt zwischen den USA einerseits sowie Europa und China ande- rerseits tat sein √ºbriges. Zudem ging Italien im Rahmen seiner Haushaltspolitik auf Konfronta- tionskurs zur Europ√§ischen Uni- on (EU). Dar√ºber hinaus verun- sicherte weiterhin der drohende Brexit die Marktteilnehmer, insbesondere dahingehend, ob der m√∂gliche Austritt des Ver- einigten K√∂nigreiches aus der EU geordnet oder - ohne ein √úbereinkommen - ungeordnet vollzogen wird. Im Gegensatz zu den politischen Unsicher- heiten standen die bislang eher zuversichtlichen, konventionel- len Wirtschaftsindikatoren. So expandierte die Weltwirtschaft kr√§ftig, wenngleich sich deren Wachstum im Laufe der zwei- ten Jahresh√§lfte 2018 etwas verlangsamte. Die Geldpolitik war historisch gesehen immer noch sehr locker, trotz der welt- weit sehr hohen Verschuldung und der Zinserh√∂hungen der US-Notenbank.\\nEntwicklung der Leitzinsen in den USA und im Euroraum %p.a.\\nZinswende nach Rekordtiefs\\nbei Anleiherenditen? Im Berichtszeitraum kam es an den Anleihem√§rkten - wenn auch uneinheitlich und unter- schiedlich stark ausgepr√§gt - unter Schwankungen zu stei- genden Renditen auf teilweise immer noch sehr niedrigem Niveau, begleitet von nachge- benden Kursen. Dabei konnten sich die Zinsen vor allem in den USA weiter von ihren histori- schen Tiefs l√∂sen. Gleichzeitig wurde die Zentralbankdivergenz zwischen den USA und dem Euroraum immer deutlicher. An- gesichts des Wirtschaftsbooms in den USA hob die US-Noten- bank Fed im Berichtszeitraum den Leitzins in vier Schritten weiter um einen Prozentpunkt auf einen Korridor von 2,25% - 2,50% p.a. an. Die Europ√§ische Zentralbank (EZB) hingegen hielt an ihrer Nullzinspolitik fest und die Bank of Japan belie√ü ihren Leitzins bei -0,10% p.a. Die Fed begr√ºndete ihre Zinser- h√∂hungen mit der Wachstums- beschleunigung und der Voll- besch√§ftigung am Arbeitsmarkt in den USA. Zinserh√∂hungen erm√∂glichten der US-Notenbank einer √úberhitzung der US-Wirt- schaft vorzubeugen, die durch die prozyklische expansive\\n-1 u u u u u u u u u u u 12/08 12/09 12/10 12/11 12/12 12/13 12/14 12/15 12/16 12/17 12/18\\nBE Fed-Leitzins\\nQuelle: Thomson Financial Datastream\\nBE E28-Leitzins\\nStand: 31.12.2018\\nFiskalpolitik des US-Pr√§sidenten Donald Trump in Form von Steuererleichterungen und einer Erh√∂hung der Staatsausgaben noch befeuert wurde. Vor die- sem Hintergrund verzeichneten die US-Bondm√§rkte einen sp√ºr- baren Renditeanstieg, der mit merklichen Kurserm√§√üigungen einherging. Per saldo stiegen die Renditen zehnj√§hriger US- Staatsanleihen auf Jahressicht von 2,4% p.a. auf 3,1% p.a.\\nDiese Entwicklung in den USA hatte auf den Euroraum jedoch nur phasenweise und partiell, insgesamt aber kaum einen zinstreibenden Effekt auf Staats- anleihen aus den europ√§ischen Kernm√§rkten wie beispielsweise Deutschland und Frankreich. So gaben zehnj√§hrige deutsche Bundesanleihen im Jahresver- lauf 2018 unter Schwankungen per saldo sogar von 0,42% p.a. auf 0,25% p. a. nach. Vielmehr standen die Anleihem√§rkte der Eurol√§nder - insbeson- dere ab dem zweiten Quartal 2018 - unter dem Einfluss der politischen und wirtschaftlichen Entwicklung in der Eurozone, vor allem in den L√§ndern mit hoher Verschuldung und nied- rigem Wirtschaftswachstum. In den Monaten Mai und Juni\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pipe.analyze(path=image_path)\n",
    "df.reset_state()\n",
    "dp = next(iter(df))\n",
    "dp.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we got it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-doc-pt",
   "language": "python",
   "name": "deep-doc-pt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
